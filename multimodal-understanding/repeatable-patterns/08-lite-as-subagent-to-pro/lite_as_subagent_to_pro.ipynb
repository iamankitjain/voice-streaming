{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Nova Lite as a sub-agent to Nova Pro model\n",
    "\n",
    "In this notebook, we'll demonstrate how to analyze Amazon's 2023 quartely earnings reports using Nova Pro model to extract relevant information from quarterly earnings PDFs. We'll then use Nova Lite to answer our questions and create a graph using matplotlib to complement the responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup\n",
    "Let's install the required libraries and set up the Nova API client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install IPython PyMuPDF matplotlib --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets import the modules needed for this exercise\n",
    "import boto3\n",
    "import json\n",
    "from typing import Optional\n",
    "import fitz\n",
    "import base64\n",
    "from PIL import Image\n",
    "import io\n",
    "import requests\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Set up Bedrock Nova API client\n",
    "client = boto3.client(\n",
    "    \"bedrock-runtime\",\n",
    "    region_name=\"us-east-1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Gather the documents and ask a question\n",
    "We will be using Amazon's financial statements from the 2023 and 2024 financial year and asking questions on net sales for the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Amazon's earnings release PDF URLs from 2023 and 2024. In this example we will consider 2023 quarterly\n",
    "# results.\n",
    "\n",
    "#2024 \n",
    "#     \"https://s2.q4cdn.com/299287126/files/doc_financials/2024/q1/AMZN-Q1-2024-Earnings-Release.pdf\",\n",
    "#     \"https://s2.q4cdn.com/299287126/files/doc_financials/2024/q2/AMZN-Q2-2024-Earnings-Release.pdf\",\n",
    "#     \"https://s2.q4cdn.com/299287126/files/doc_financials/2024/q3/AMZN-Q3-2024-Earnings-Release.pdf\"\n",
    "\n",
    "pdf_urls = [ \n",
    "    \"https://s2.q4cdn.com/299287126/files/doc_financials/2023/q1/Q1-2023-Amazon-Earnings-Release.pdf\",\n",
    "    \"https://s2.q4cdn.com/299287126/files/doc_financials/2023/q2/Q2-2023-Amazon-Earnings-Release.pdf\",\n",
    "    \"https://s2.q4cdn.com/299287126/files/doc_financials/2023/q3/AMZN-Q3-2023-Earnings-Release.pdf\",\n",
    "    \"https://s2.q4cdn.com/299287126/files/doc_financials/2023/q4/AMZN-Q4-2023-Earnings-Release.pdf\"    \n",
    "]\n",
    "\n",
    "# User's question\n",
    "QUESTION = \"How did Amazon's net sales change quarter to quarter in the 2023 financial year and what contributed to the changes?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Download and convert PDFs to images\n",
    "In this step, we'll define functions to download the earnings PDFs and convert them to base64-encoded PNG images. We need to do this as these PDFs are full of tables which are hard to parse with traditional PDF parsers. It's easier if we just convert them to images and pass the images to Nova Model.\n",
    "\n",
    "`download_pdf`: function downloads a PDF file from the URL's provided in the previous step and saves it to the specified folder.\n",
    "`pdf_to_base64_pngs`: function converts a PDF to a list of base64-encoded PNG images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to download PDF file from an URL and save it to a specified folder\n",
    "def download_pdf(url, folder):\n",
    "    try:\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()\n",
    "        file_name = os.path.join(folder, url.split(\"/\")[-1])\n",
    "        with open(file_name, \"wb\") as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                file.write(chunk)\n",
    "        return file_name\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Failed to download PDF from {url}: {e}\")\n",
    "        return None\n",
    "#Function to convert PDF files to a list of base64-encoded PNG images\n",
    "def pdf_to_base64_pngs(pdf_path, quality=75, max_size=(1024, 1024)):\n",
    "    base64_encoded_pngs = []\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        for page in doc:\n",
    "            pix = page.get_pixmap(matrix=fitz.Matrix(300/72, 300/72))\n",
    "            image = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "            if image.size[0] > max_size[0] or image.size[1] > max_size[1]:\n",
    "                image.thumbnail(max_size, Image.Resampling.LANCZOS)\n",
    "            with io.BytesIO() as image_data:\n",
    "                image.save(image_data, format='PNG', optimize=True, quality=quality)\n",
    "                base64_encoded = base64.b64encode(image_data.getvalue()).decode('utf-8')\n",
    "                base64_encoded_pngs.append(base64_encoded)\n",
    "    return base64_encoded_pngs\n",
    "\n",
    "#Function to return both the local path of the PDF files and the list of base64-encoded images\n",
    "def process_pdf(url, folder):\n",
    "    pdf_path = download_pdf(url, folder)\n",
    "    if pdf_path:\n",
    "        return pdf_path, pdf_to_base64_pngs(pdf_path)\n",
    "    return None\n",
    "\n",
    "# Folder to save the downloaded PDFs\n",
    "folder = \"../downloads/pdfs\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# Process PDFs concurrently\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    pdf_results = list(executor.map(\n",
    "        process_pdf, pdf_urls, [folder] * len(pdf_urls)))\n",
    "\n",
    "    # Remove any None values (failed downloads or conversions) from results\n",
    "pdf_results = [r for r in pdf_results if r is not None]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Generate a specific prompt for Nova Lite using Pro\n",
    "Let's use Nova Pro Model as an orchestrator and have it write specific prompt for Lite Model based on the user provided question.\n",
    "\n",
    "Instructions:\n",
    "Summarize the overall trend in Amazon's net sales for the 2023 financial year.\n",
    "Highlight the significant changes and the corresponding contributing factors.\n",
    "Offer insights into how these factors might impact future performance and what strategies Amazon might consider based on the analysis.\n",
    "\n",
    "These prompts will guide the Nova model through the process of analyzing Amazon's net sales data, identifying trends, and understanding the contributing factors, ultimately providing a comprehensive analysis of the company'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt_for_lite(question: str) -> Optional[str]:\n",
    "    if not question or not isinstance(question, str):\n",
    "        raise ValueError(\"Question must be a non-empty string\")\n",
    "\n",
    "    try:\n",
    "        request_body = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"text\": f'''Based on the following question,\n",
    "                            please generate a specific prompt for an LLM agent to extract relevant information from an earning's report PDF.\n",
    "                            Each sub-agent only has access to a single quarter's earnings report.\n",
    "                            Output only the prompt and nothing else.\n",
    "                            \\n\\nQuestion: {question}'''\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"inferenceConfig\": {\n",
    "                \"max_new_tokens\": 300,\n",
    "                \"top_p\": 0.9,\n",
    "                \"top_k\": 20,\n",
    "                \"temperature\": 0.7,\n",
    "            }\n",
    "        }\n",
    "\n",
    "        response = client.invoke_model(\n",
    "            modelId=\"us.amazon.nova-pro-v1:0\",\n",
    "            body=json.dumps(request_body)\n",
    "        )\n",
    "\n",
    "        model_response = json.loads(response[\"body\"].read().decode('utf-8'))\n",
    "        content_text = model_response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "        print(\"\\n\\033[1m[Formatted Response Content Text]\\033[0m\")\n",
    "        print(content_text)\n",
    "        print('-' * 60)\n",
    "        return content_text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating prompt: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Generate the lite prompt\n",
    "    lite_prompt = generate_prompt_for_lite(QUESTION)\n",
    "    if not lite_prompt:\n",
    "        print(\"Failed to generate prompt. Exiting.\")\n",
    "        exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Extract information from PDFs\n",
    "Now, let's define our question and extract information from the PDFs using sub-agent Lite models. We format the information from each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def extract_info(pdf_path, base64_encoded_pngs, lite_prompt):\n",
    "    request_body = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"image\": {\n",
    "                            \"source\": {\"bytes\": base64_encoded_png},\n",
    "                            \"format\": \"png\"\n",
    "                        }\n",
    "                    } for base64_encoded_png in base64_encoded_pngs\n",
    "                ] + [\n",
    "                    {\n",
    "                        \"text\": lite_prompt\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    response = client.invoke_model(\n",
    "        modelId=\"us.amazon.nova-lite-v1:0\",\n",
    "        body=json.dumps(request_body)\n",
    "    )\n",
    "\n",
    "    model_response = json.loads(response[\"body\"].read().decode('utf-8'))\n",
    "    return model_response[\"output\"][\"message\"][\"content\"][0][\"text\"], pdf_path\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Extract information from PDFs\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        extracted_info_list = list(executor.map(\n",
    "            lambda x: extract_info(x[0], x[1], lite_prompt), pdf_results))\n",
    "\n",
    "    # Process and display the extracted information\n",
    "    extracted_info = \"\"\n",
    "    for info, pdf_path in extracted_info_list:\n",
    "        quarter = os.path.basename(pdf_path).split(\"-\")[1]  # Extracting quarter from filename\n",
    "        extracted_info += f\"<info quarter=\\\"{quarter}\\\">{info}</info>\\n\"\n",
    "\n",
    "    print(extracted_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract information from the PDFs concurrently using sub-agent models and combine the extracted information. We then prepare the messages for the powerful Pro model, including the question and the extracted information, and ask it to generate a response and matplotlib code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Pass the information to Nova Pro model to generate Python code to create a graph\n",
    "Now that we have fetched the information from each PDF using the sub-agents, let's call Pro model to actually answer the question and write code to create a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the messages for the Pro model\n",
    "request_body = {\n",
    "    \"messages\": [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"text\": f'''Based on the following extracted information from Amazon's earnings releases, \n",
    "             please provide a response to the question: {QUESTION}\\n\\n\n",
    "             Also, please generate Python code using the matplotlib library to accompany your response. \n",
    "             Enclose the code within <python_code> tags.\\n\\nExtracted Information:\\n{extracted_info}'''}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "}\n",
    "\n",
    "# Generate the matplotlib code using the powerful model\n",
    "response = client.invoke_model(\n",
    "            modelId=\"us.amazon.nova-pro-v1:0\",\n",
    "            body=json.dumps(request_body)\n",
    ")\n",
    "\n",
    "model_response = json.loads(response[\"body\"].read().decode('utf-8'))\n",
    "content_text = model_response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "print(\"\\n\\033[1m[Formatted Response Content Text]\\033[0m\")\n",
    "print(content_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Extract response and execute Matplotlib code\n",
    "Finally, let's extract the matplotlib code from the generated response above and use it to visualize the revenue growth trend.\n",
    "\n",
    "We define the ```extract_code_and_response``` function to extract the matplotlib code and non-code response from the generated response in the previous step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def extract_code(response):\n",
    "    start = response.find(\"<python>\")\n",
    "    end = response.find(\"</python>\")\n",
    "    if start != -1 and end != -1:\n",
    "        return response[start+6:end].strip(), response[:start].strip()\n",
    "    return None, response.strip()\n",
    "\n",
    "# Assuming content_text is defined\n",
    "code, text = extract_code(content_text)\n",
    "\n",
    "print(text)\n",
    "if code:\n",
    "    try:\n",
    "        exec(code)\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing code: {e}\")\n",
    "        \n",
    "        \n",
    "# Data for the net sales in each quarter\n",
    "quarters = ['Q1 2023', 'Q2 2023', 'Q3 2023', 'Q4 2023']\n",
    "net_sales = [127.4, 129.4, 130.3, 133.0]\n",
    "\n",
    "# Plotting the net sales\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(quarters, net_sales, marker='o', linestyle='-', color='b', label='Net Sales (in billions)')\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title('Amazon Net Sales by Quarter in 2023')\n",
    "plt.xlabel('Quarter')\n",
    "plt.ylabel('Net Sales (in billions)')\n",
    "plt.grid(True)\n",
    "\n",
    "# Adding labels for each data point\n",
    "for i, value in enumerate(net_sales):\n",
    "    plt.text(quarters[i], value, f'{value:.1f}', ha='right', va='bottom')\n",
    "\n",
    "# Adding legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agi-dev-3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
