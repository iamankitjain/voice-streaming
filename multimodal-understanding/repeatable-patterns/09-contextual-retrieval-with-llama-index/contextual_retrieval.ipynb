{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4bf9d00-00ef-4099-a66d-b2fc4f433504",
   "metadata": {},
   "source": [
    "# Contextual retrieval with Nova Lite and llama-index\n",
    "In this notebook, you will learn how to improve the context in your vector store using contextual retrieval with Amazon Bedrock and the Nova family of models. We will be using Llama-index pipelines to orchestrate and automate the workflow execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09fd21c-f841-4e65-b02b-664519b46bbf",
   "metadata": {},
   "source": [
    "### 1) Setup\n",
    "* Install python modules\n",
    "* Import required classes/functions\n",
    "* Set all static variables\n",
    "* Define custom classes/functions required\n",
    "* Initialise clients (AWS/llama-index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0817df69",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q --upgrade pip\n",
    "%pip install -q --upgrade packaging\n",
    "%pip install -q llama-index-core\n",
    "%pip install -q llama-index-embeddings-bedrock\n",
    "%pip install -q llama-index-llms-bedrock-converse\n",
    "%pip install -q llama_index_postprocessor_colbert_rerank\n",
    "%pip install -q llama-index-readers-web\n",
    "%pip install -q llama-index-retrievers-bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7ea414-395a-4b05-b966-aae97fea6ccc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import copy\n",
    "import html2text\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "import requests\n",
    "import Stemmer\n",
    "from typing import List\n",
    "\n",
    "from botocore.config import Config\n",
    "from llama_index.core import Settings, VectorStoreIndex, QueryBundle\n",
    "from llama_index.core.evaluation import (\n",
    "    RetrieverEvaluator,\n",
    "    generate_question_context_pairs\n",
    ")\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.schema import TransformComponent, NodeWithScore\n",
    "from llama_index.embeddings.bedrock import BedrockEmbedding\n",
    "from llama_index.llms.bedrock_converse import BedrockConverse\n",
    "from llama_index.postprocessor.colbert_rerank import ColbertRerank\n",
    "from llama_index.readers.web import SimpleWebPageReader\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "from llama_index.core.retrievers import BaseRetriever, VectorIndexRetriever\n",
    "\n",
    "AWS_REGION = \"us-east-1\"\n",
    "BEDROCK_EMBEDDING_MODEL = \"cohere.embed-english-v3\"\n",
    "BEDROCK_TEXT_GENERATION_MODEL = \"us.amazon.nova-lite-v1:0\"\n",
    "BEDROCK_MAX_TOKENS = 5000\n",
    "BEDROCK_TEMPERATURE = 0.0\n",
    "BEDROCK_BOTOCORE_MAX_RETRIES = 20\n",
    "LLAMA_INDEX_CHUNK_SIZE=512\n",
    "LLAMA_INDEX_CHUNK_OVERLAP=51\n",
    "LLAMA_INDEX_INGESTION_DOCUMENTS=[\n",
    "    \"https://www.aboutamazon.com/news/company-news/amazon-ceo-andy-jassy-2022-letter-to-shareholders\",\n",
    "    \"https://www.aboutamazon.com/news/company-news/ceo-andy-jassys-2023-letter-to-shareholders\"\n",
    "]\n",
    "LLAMA_INDEX_RETRIEVAL_EVALUATION_METRICS = [\n",
    "    \"hit_rate\", \n",
    "    \"mrr\", \n",
    "    \"recall\"\n",
    "]\n",
    "LLAMA_INDEX_RETRIEVAL_TOP_K=5\n",
    "LLAMA_INDEX_RERANKER=\"colbert-ir/colbertv2.0\"\n",
    "LLAMA_INDEX_SAMPLE_DATA_NUM_QUESTIONS_PER_CHUNK=2\n",
    "\n",
    "class LlamaIndexEmbeddingBM25RerankerRetriever(BaseRetriever):\n",
    "    \"\"\"\n",
    "    A hybrid retriever that combines vector-based and BM25 retrieval with reranking.\n",
    "\n",
    "    This retriever implements a multi-stage retrieval process:\n",
    "    1. Retrieves documents using a vector-based retriever (semantic search)\n",
    "    2. Retrieves documents using BM25 (lexical search)\n",
    "    3. Combines both result sets\n",
    "    4. Reranks the combined results using a ColBERT reranker\n",
    "\n",
    "    The final output is a reranked list of documents that leverages both semantic and lexical matching,\n",
    "    potentially providing better search results than either method alone.\n",
    "\n",
    "    Attributes:\n",
    "        _vector_retriever (VectorIndexRetriever): Retriever for vector/embedding-based search\n",
    "        bm25_retriever (BM25Retriever): Retriever for BM25 lexical search\n",
    "        reranker (ColbertRerank): Reranker to score and sort combined results\n",
    "\n",
    "    Example:\n",
    "        retriever = LlamaIndexEmbeddingBM25RerankerRetriever(\n",
    "            vector_retriever=vector_retriever,\n",
    "            bm25_retriever=bm25_retriever,\n",
    "            reranker=reranker\n",
    "        )\n",
    "        results = retriever.retrieve(query)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vector_retriever: VectorIndexRetriever,\n",
    "        bm25_retriever: BM25Retriever,\n",
    "        reranker: ColbertRerank,\n",
    "    ) -> None:\n",
    "        \"\"\"Init params.\"\"\"\n",
    "\n",
    "        self._vector_retriever = vector_retriever\n",
    "        self.bm25_retriever = bm25_retriever\n",
    "        self.reranker = reranker\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        \"\"\"Retrieve nodes given query.\"\"\"\n",
    "\n",
    "        vector_nodes = self._vector_retriever.retrieve(query_bundle)\n",
    "        bm25_nodes = self.bm25_retriever.retrieve(query_bundle)\n",
    "\n",
    "        vector_nodes.extend(bm25_nodes)\n",
    "\n",
    "        retrieved_nodes = self.reranker.postprocess_nodes(\n",
    "            vector_nodes, query_bundle\n",
    "        )\n",
    "\n",
    "        return retrieved_nodes\n",
    "\n",
    "class LlamaIndexContextualEnrichment(TransformComponent):\n",
    "    \"\"\"\n",
    "    A transformation component that enriches document nodes with contextual information using LLM.\n",
    "\n",
    "    This class processes nodes from document chunks (typically from Amazon shareholder letters) \n",
    "    and adds contextual metadata by analyzing each chunk within its full document context.\n",
    "\n",
    "    The enrichment process:\n",
    "    1. Retrieves the full source document for each node\n",
    "    2. Converts HTML content to plain text\n",
    "    3. Uses LLM to generate contextual information by analyzing the chunk within the complete document\n",
    "    4. Adds the context as metadata to each node\n",
    "\n",
    "    Parameters:\n",
    "        nodes: List of document nodes to be enriched\n",
    "\n",
    "    Returns:\n",
    "        List[Node]: New list of nodes with added contextual metadata\n",
    "\n",
    "    Attributes:\n",
    "        web_page_content (dict): Cache of retrieved web page contents\n",
    "\n",
    "    Note:\n",
    "        - Requires an active internet connection to fetch source documents\n",
    "        - Depends on external libraries: requests, html2text\n",
    "        - Assumes nodes have valid source URL relationships\n",
    "        - Uses LLM configured in Settings for context generation\n",
    "    \"\"\"\n",
    "    @classmethod\n",
    "    def __call__(self, nodes, **kwargs):\n",
    "\n",
    "        web_page_content = {}\n",
    "        node_total = len(nodes)\n",
    "        node_current_index = 1\n",
    "        nodes_new = []\n",
    "\n",
    "        for node in nodes:\n",
    "            print(f\"enriching node: {node.node_id} ({node_current_index})/{node_total}\")\n",
    "            new_node = copy.deepcopy(node)\n",
    "            for r in new_node.relationships:\n",
    "                if(str(r) == \"NodeRelationship.SOURCE\"):\n",
    "                    source_url = new_node.relationships[r].node_id\n",
    "                    if(new_node.relationships[r].node_id not in web_page_content):\n",
    "                        web_page_content[new_node.relationships[r].node_id] = requests.get(new_node.relationships[r].node_id).text\n",
    "                        web_page_content[new_node.relationships[r].node_id] = html2text.html2text(web_page_content[new_node.relationships[r].node_id])\n",
    "\n",
    "            whole_document = web_page_content[source_url]\n",
    "            prompt = f\"\"\"\n",
    "                ## Here is the source document:\n",
    "                <document>\n",
    "                {whole_document}\n",
    "                </document>\n",
    "                ## Here is the chunk we want to situate within the whole document\n",
    "                <chunk>\n",
    "                {new_node.text}\n",
    "                </chunk>\n",
    "                ## Your role\n",
    "                You are a financial document analysis specialist with expertise in annual shareholder letters,\n",
    "                particularly those from Amazon.\n",
    "                ## Your Task\n",
    "                Your task is to analyze the <chunk> from an Amazon shareholder\n",
    "                letter written by Amazon CEO and enhance its searchability and context.\n",
    "                Please give a short succinct context to situate this chunk within the overall document for the purposes of improving search retrieval of the chunk. \n",
    "                Answer only with the succinct context and nothing else.\n",
    "            \"\"\"\n",
    "            new_node.metadata['context'] = Settings.llm.complete(prompt).text\n",
    "            nodes_new.append(new_node)\n",
    "\n",
    "            node_current_index += 1\n",
    "\n",
    "        return nodes_new\n",
    "\n",
    "\n",
    "def llama_index_evaluation_print_results(name, eval_results, metrics = LLAMA_INDEX_RETRIEVAL_EVALUATION_METRICS):\n",
    "    \"\"\"\n",
    "    Display evaluation results from LlamaIndex retrieval evaluation in a formatted DataFrame.\n",
    "\n",
    "    Args:\n",
    "        name (str): The name of the retriever being evaluated.\n",
    "        eval_results (list): List of evaluation result objects containing metric values.\n",
    "        metrics (list, optional): List of metric names to include in the results. \n",
    "            Defaults to LLAMA_INDEX_RETRIEVAL_EVALUATION_METRICS.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing:\n",
    "            - 'retrievers': Name of the retriever\n",
    "            - Average values for each specified metric across all evaluation results\n",
    "\n",
    "    Example:\n",
    "        >>> eval_results = [result1, result2, result3]  # evaluation results\n",
    "        >>> df = llama_index_evaluation_print_results(\"MyRetriever\", eval_results)\n",
    "    \"\"\"\n",
    "\n",
    "    metric_dicts = []\n",
    "    for eval_result in eval_results:\n",
    "        metric_dicts.append(eval_result.metric_vals_dict)\n",
    "\n",
    "    full_df = pd.DataFrame(metric_dicts)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"retrievers\": [name],\n",
    "        **{k: [full_df[k].mean()] for k in LLAMA_INDEX_RETRIEVAL_EVALUATION_METRICS},\n",
    "    })\n",
    "\n",
    "aws_client_bedrock_runtime = boto3.client(\n",
    "    config=Config(\n",
    "        region_name=AWS_REGION,\n",
    "        retries={\n",
    "            'max_attempts': BEDROCK_BOTOCORE_MAX_RETRIES\n",
    "        }\n",
    "    ),\n",
    "    region_name=AWS_REGION,\n",
    "    service_name=\"bedrock-runtime\"\n",
    ")\n",
    "\n",
    "Settings.embed_model = BedrockEmbedding(\n",
    "    client=aws_client_bedrock_runtime,\n",
    "    model_id=BEDROCK_EMBEDDING_MODEL\n",
    ")\n",
    "\n",
    "Settings.llm = BedrockConverse(\n",
    "    client=aws_client_bedrock_runtime,\n",
    "    max_tokens=BEDROCK_MAX_TOKENS,\n",
    "    model=BEDROCK_TEXT_GENERATION_MODEL,\n",
    "    temperature=BEDROCK_TEMPERATURE\n",
    ")\n",
    "\n",
    "colbert_reranker = ColbertRerank(\n",
    "    top_n=LLAMA_INDEX_RETRIEVAL_TOP_K,\n",
    "    model=LLAMA_INDEX_RERANKER,\n",
    "    tokenizer=LLAMA_INDEX_RERANKER,\n",
    "    keep_retrieval_score=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630b07b9-db5f-4d76-b4b1-8d284708fa53",
   "metadata": {},
   "source": [
    "### 2) Scrape content\n",
    "* Define web crawler, and specify documents to ingest\n",
    "* Split documents into chunks (to fit within embedding model constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4481653-f216-4579-864a-61453b288066",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llama_index_documents = SimpleWebPageReader(\n",
    "    html_to_text=True\n",
    ").load_data(\n",
    "    LLAMA_INDEX_INGESTION_DOCUMENTS\n",
    ")\n",
    "print(f\"number of documents loaded: {len(llama_index_documents)}\")\n",
    "llama_index_document_splitter = SentenceSplitter(\n",
    "    chunk_size=LLAMA_INDEX_CHUNK_SIZE,\n",
    "    chunk_overlap=LLAMA_INDEX_CHUNK_OVERLAP\n",
    ")\n",
    "llama_index_documents_split = llama_index_document_splitter(\n",
    "    llama_index_documents\n",
    ")\n",
    "print(f\"documents split into chunks: {len(llama_index_documents_split)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717118fe-241f-4f80-9f0f-2525ff93a47b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3a) Create retriever-basic from content\n",
    "* create an ingestion pipeline\n",
    "* execute the pipeline\n",
    "* save the cache of the pipeline to disk\n",
    "* move the pipeline output into an in memory index\n",
    "* create a retriever to retrieve documents from the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a339cc1-5d92-4adc-8c9c-51e31d8006d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llama_index_pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        Settings.embed_model\n",
    "    ]\n",
    ")\n",
    "\n",
    "llama_index_nodes = llama_index_pipeline.run(\n",
    "    documents=llama_index_documents_split,\n",
    "    show_progress=True\n",
    ")\n",
    "print(f\"chunks ingested into index: {len(llama_index_nodes)}\")\n",
    "\n",
    "llama_index_pipeline.persist(\"sam_test_pipeline_cache\")\n",
    "\n",
    "llama_index_index = VectorStoreIndex(\n",
    "    nodes=llama_index_nodes,\n",
    ")\n",
    "\n",
    "llama_index_retriever = llama_index_index.as_retriever(\n",
    "    similarity_top_k=LLAMA_INDEX_RETRIEVAL_TOP_K\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa3792b-f0f5-4ecc-ae25-01620e07bc86",
   "metadata": {},
   "source": [
    "### 3b) Create retriever-enriched from content\n",
    "* create an ingestion pipeline\n",
    "* execute the pipeline\n",
    "* save the cache of the pipeline to disk\n",
    "* move the pipeline output into an in memory index\n",
    "* create a retriever to retrieve documents from the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2a334a-acd9-425b-a0ba-89477a1d2517",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llama_index_pipeline_enriched = IngestionPipeline(\n",
    "    transformations=[\n",
    "        LlamaIndexContextualEnrichment(),\n",
    "        Settings.embed_model\n",
    "    ]\n",
    ")\n",
    "\n",
    "llama_index_nodes_enriched = llama_index_pipeline_enriched.run(\n",
    "    documents=llama_index_documents_split,\n",
    "    show_progress=True\n",
    ")\n",
    "print(f\"chunks ingested into index (enriched): {len(llama_index_nodes_enriched)}\")\n",
    "\n",
    "llama_index_pipeline_enriched.persist(\"sam_test_pipeline_cache_enriched\")\n",
    "\n",
    "llama_index_index_enriched = VectorStoreIndex(\n",
    "    nodes=llama_index_nodes_enriched,\n",
    ")\n",
    "\n",
    "llama_index_retriever_enriched = llama_index_index_enriched.as_retriever(\n",
    "    similarity_top_k=LLAMA_INDEX_RETRIEVAL_TOP_K\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0952959-c0e8-4ba2-a36b-24e2d9d01837",
   "metadata": {},
   "source": [
    "### 3c) Create retriever-enriched-bm25 from content\n",
    "* using enriched index, create a BM25 retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75aa58c-6280-45fc-995b-9d8032266187",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llama_index_retriever_bm25 = BM25Retriever.from_defaults(\n",
    "    index=llama_index_index_enriched,\n",
    "    similarity_top_k=LLAMA_INDEX_RETRIEVAL_TOP_K,\n",
    "    stemmer=Stemmer.Stemmer(\"english\"),\n",
    "    language=\"english\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c11811b-1a06-476f-a456-251072962093",
   "metadata": {},
   "source": [
    "### 3d) Create retriever-enriched-bm25-with-reranker from content\n",
    "* using both the enriched retriever AND the BM25 retriever, create a hybrid retriever that also adds re-ranking capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8283e287-48d6-471e-b5bb-8c639601d6a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llama_index_embedding_bm25_retriever_reranker = LlamaIndexEmbeddingBM25RerankerRetriever(\n",
    "    llama_index_retriever_enriched,\n",
    "    llama_index_retriever_bm25,\n",
    "    reranker=colbert_reranker\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b1c47f-4dfc-4f0f-bf16-a64bff808fe1",
   "metadata": {},
   "source": [
    "### 4) Generate Testing Data\n",
    "* setup asyncio for async processing\n",
    "* iterate over split documents, and generate \"n\" sample questions based on the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4c547b-2827-4269-b7b5-78a941bf917c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nest_asyncio.apply()\n",
    "\n",
    "llama_index_dataset_qa = generate_question_context_pairs(\n",
    "    nodes=llama_index_documents_split,\n",
    "    num_questions_per_chunk=LLAMA_INDEX_SAMPLE_DATA_NUM_QUESTIONS_PER_CHUNK,\n",
    "    qa_generate_prompt_tmpl=\"\"\"\n",
    "        ##Context information\n",
    "        ---------------------\n",
    "        {context_str}\n",
    "        ---------------------\n",
    "\n",
    "        ##Your role\n",
    "        You are an expert financial analyst specialized in creating evaluation questions for RAG systems, \n",
    "        with deep knowledge of how to evaluate document retrieval systems using a given Amazon shareholders letter context.\n",
    "\n",
    "        ##Task\n",
    "        A web-crawler retrieved the provided context information from the aboutamazon.com website, which hosts Amazon shareholders letters.\n",
    "        Your task is to analyze this context and setup {num_questions_per_chunk} questions for an upcoming evaluation. \n",
    "        Restrict the questions to the content from the provided context information.\n",
    "\n",
    "        ##Output Requirements\n",
    "        - Generate exactly {num_questions_per_chunk} questions\n",
    "        - Each question must be answerable solely from the provided context\n",
    "        - Questions must be self-contained without requiring external knowledge\n",
    "        - Present only the questions with no additional text\n",
    "        - Number each question\n",
    "        - Each question should be on a new line\n",
    "        - Generate questions based solely on the actual content of the shareholders letter, ignoring any website navigation elements, headers, \n",
    "        footers, or menu items. Focus only on substantive information from the letter itself.\n",
    "    \"\"\",\n",
    "    llm=Settings.llm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5947bd8-d05a-496d-a798-1be6b0fa79ee",
   "metadata": {},
   "source": [
    "### 5a) Evaluate retriever-original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c51457-b867-49bb-89ee-b6917c45e697",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llama_index_evaluator = RetrieverEvaluator.from_metric_names(\n",
    "    retriever=llama_index_retriever,\n",
    "    metric_names=LLAMA_INDEX_RETRIEVAL_EVALUATION_METRICS\n",
    ")\n",
    "results = await llama_index_evaluator.aevaluate_dataset(llama_index_dataset_qa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55deaf0-d051-4de5-8abd-cc45cf3bd23f",
   "metadata": {},
   "source": [
    "### 5b) Evaluate retriever-enriched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b65b54-ac06-41eb-90d2-159859b7fff2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llama_index_evaluator_enriched = RetrieverEvaluator.from_metric_names(\n",
    "    retriever=llama_index_retriever_enriched,\n",
    "    metric_names=LLAMA_INDEX_RETRIEVAL_EVALUATION_METRICS\n",
    ")\n",
    "results_enriched = await llama_index_evaluator_enriched.aevaluate_dataset(llama_index_dataset_qa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01dc4c6-bd0c-4f5f-8961-cbcb2e6bc567",
   "metadata": {},
   "source": [
    "### 5c) Evaluate retriever-enriched-bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f5f20d-e41c-4184-b7c9-663e1ec1362a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llama_index_evaluator_bm25 = RetrieverEvaluator.from_metric_names(\n",
    "    retriever=llama_index_retriever_bm25,\n",
    "    metric_names=LLAMA_INDEX_RETRIEVAL_EVALUATION_METRICS\n",
    ")\n",
    "results_bm25 = await llama_index_evaluator_bm25.aevaluate_dataset(llama_index_dataset_qa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3580c2ab-2eff-41b9-a70b-822757a967be",
   "metadata": {},
   "source": [
    "### 5d) Evaluate retriever-enriched-bm25-with-reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf6103f-4f43-4489-bc16-99adacc31184",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llama_index_evaluator_hybrid_search = RetrieverEvaluator.from_metric_names(\n",
    "    retriever=llama_index_embedding_bm25_retriever_reranker,\n",
    "    metric_names=LLAMA_INDEX_RETRIEVAL_EVALUATION_METRICS\n",
    ")\n",
    "results_hybrid = await llama_index_evaluator_hybrid_search.aevaluate_dataset(llama_index_dataset_qa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3eba8eb-c3d6-4bdd-86de-c8e30a8759ea",
   "metadata": {},
   "source": [
    "### 6) Print Results\n",
    "* using all the evaluations generated earlier, combine into a single dataframe and print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f8615f-1388-45f8-bae0-d241a426d990",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.concat(\n",
    "    [\n",
    "        llama_index_evaluation_print_results(\"retriever-original\", results),\n",
    "        llama_index_evaluation_print_results(\"retriever-enriched\", results_enriched),\n",
    "        llama_index_evaluation_print_results(\"retriever-enriched-bm25\", results_bm25),\n",
    "        llama_index_evaluation_print_results(\"retriever-enriched-hybrid\", results_hybrid)\n",
    "    ],\n",
    "    ignore_index=True,\n",
    "    axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5651fef7-fbf8-4c08-8df3-8248f4b831ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agi-dev-3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
