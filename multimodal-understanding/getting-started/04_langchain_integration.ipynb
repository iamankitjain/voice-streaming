{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d932ae5-c2b1-4de8-865f-aa28509c33ee",
   "metadata": {},
   "source": [
    "## Langchain Integration for Nova\n",
    "\n",
    "To aid in the development of applications with Nova models; Langchain support has been added for multimodal and agentic workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7419d32-d280-41a9-922a-c210eae828b9",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0cdbc4-698b-4992-9468-a3152d40edd0",
   "metadata": {},
   "source": [
    "#### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e090009-940a-4f23-a9b9-141542376c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q langchain langchain_community faiss_cpu pypdf --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d9169b-3f39-465a-9f80-50976b3510dd",
   "metadata": {},
   "source": [
    "**Note**: Micro can be used for text understanding use case and Lite and Pro for multimodal understanding use cases.\n",
    "\n",
    "- Nova Micro: \"us.amazon.nova-micro-v1:0\"\n",
    "- Nova Lite: \"us.amazon.nova-lite-v1:0\"\n",
    "- Nova Pro: \"us.amazon.nova-pro-v1:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42115341-e153-45f8-9d3e-d2971f722c4b",
   "metadata": {},
   "source": [
    "## Model Invocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e03481-0e86-475d-b84a-dba277ba7eb4",
   "metadata": {},
   "source": [
    "#### Text Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f0bb9a-df70-484e-9823-1b474363678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrockConverse\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "llm = ChatBedrockConverse(\n",
    "    model_id=\"us.amazon.nova-lite-v1:0\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    (\"system\", \"Provide three alternative song titles for a given user title\"),\n",
    "    (\"user\", \"Teardrops on My Guitar\"),\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "print(f\"Request ID: {response.id}\")\n",
    "response.pretty_print()\n",
    "\n",
    "\n",
    "# Here we can pass the chat history to the model to ask follow up questions\n",
    "multi_turn_messages = [\n",
    "    *messages,\n",
    "    response,\n",
    "    HumanMessage(content=\"Select your favorite and tell me why\"),\n",
    "]\n",
    "\n",
    "response = llm.invoke(multi_turn_messages)\n",
    "print(f\"\\n\\nRequest ID: {response.id}\")\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31e2084-5240-4a4f-a2e5-56ed303fb5ac",
   "metadata": {},
   "source": [
    "#### Image Understanding\n",
    "\n",
    "You are able to pass various media types to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766bbdff-bdf5-4d5d-ab5b-a324622d40f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "image_path = \"media/sunset.png\"\n",
    "Image(filename=image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e552f1-40c1-4921-9668-44da4e079aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "llm = ChatBedrockConverse(\n",
    "    model=\"us.amazon.nova-lite-v1:0\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "with open(image_path, \"rb\") as image_file:\n",
    "    binary_data = image_file.read()\n",
    "\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "        {\"image\": {\"format\": \"png\", \"source\": {\"bytes\": binary_data}}},\n",
    "        {\"text\": \"Provide a summary of this photo\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = llm.invoke([message])\n",
    "print(f\"\\n\\nRequest ID: {response.id}\")\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884decd3-7ea1-47b4-bff4-188d412664fb",
   "metadata": {},
   "source": [
    "#### Video Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee15b13-6064-4a31-98a1-d067edb8bacb",
   "metadata": {},
   "outputs": [],
   "source": "video_path = \"media/the-sea.mp4\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401e61fc-f354-4421-a46d-522d10d1a2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrockConverse\n",
    "\n",
    "llm = ChatBedrockConverse(\n",
    "    model=\"us.amazon.nova-lite-v1:0\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "with open(video_path, \"rb\") as video_file:\n",
    "    binary_data = video_file.read()\n",
    "\n",
    "\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "        {\"video\": {\"format\": \"mp4\", \"source\": {\"bytes\": binary_data}}},\n",
    "        {\"type\": \"text\", \"text\": \"Describe the following video\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = llm.invoke([message])\n",
    "print(f\"\\n\\nRequest ID: {response.id}\")\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace6d076-16dd-4285-b8cc-862f1c6e0e0d",
   "metadata": {},
   "source": [
    "#### Streaming\n",
    "\n",
    "Streaming is also supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f1db1f-01a4-43da-af72-a3a50954a8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrockConverse\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatBedrockConverse(\n",
    "    model=\"us.amazon.nova-lite-v1:0\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chain = llm | StrOutputParser()\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are an author with experience writing creative novels\"),\n",
    "    HumanMessage(\n",
    "        content=\"Write an outlin for a novel about a wizard named Theodore graduating from college\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "for chunk in chain.stream(messages):\n",
    "    print(chunk, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fb633d-a49c-4a4b-9869-0fdb995ca8dc",
   "metadata": {},
   "source": [
    "## Agent Workflows\n",
    "\n",
    "The Nova model is capable of handling tool calling and agentic workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dbb61d-ec8e-489a-a012-fad5c6a35341",
   "metadata": {},
   "source": [
    "#### Binding Tools\n",
    "\n",
    "When using a model for tool calling you can take advantage of the bind tools method. This will pass a formatted tool config to the model. We recommend when taking advantage of tool calling or agentic workflows to use greedy decoding values. This means temperature=1, topP=1, topK=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288f6941-ebc7-45b0-b6dc-9fe201cc2197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrockConverse\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "tools = [multiply]\n",
    "\n",
    "llm_with_tools = ChatBedrockConverse(\n",
    "    model=\"us.amazon.nova-lite-v1:0\",\n",
    "    temperature=1,\n",
    "    top_p=1,\n",
    "    additional_model_request_fields={\n",
    "        \"inferenceConfig\": {\n",
    "            \"topK\": 1\n",
    "        }\n",
    "    },\n",
    ").bind_tools(tools)\n",
    "\n",
    "response = llm_with_tools.invoke([(\"user\", \"What is 8*8\")])\n",
    "\n",
    "print(\"[Model Response]\\n\")\n",
    "print(response.content)\n",
    "\n",
    "print(\"\\n[Tool Calls]\\n\")\n",
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6f0cca-d9d8-4b1e-93f5-e3b8321ea754",
   "metadata": {},
   "source": [
    "#### Tool Calling Agents\n",
    "\n",
    "For full workflows you can take advantage of custom parsers that will intercept outputs of the stream and allow you to invoke tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e07d53-8381-44cb-a7de-b6e3ffcd1ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool, AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "tools = [multiply]\n",
    "\n",
    "llm_with_tools = ChatBedrockConverse(\n",
    "    model=\"us.amazon.nova-lite-v1:0\",\n",
    "    temperature=1,\n",
    "    top_p=1,\n",
    "    additional_model_request_fields={\n",
    "        \"inferenceConfig\": {\n",
    "            \"topK\": 1\n",
    "        }\n",
    "    },\n",
    ").bind_tools(tools)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "agent_executor.invoke({\"input\": \"What is 2*2?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e1ebb6",
   "metadata": {},
   "source": [
    "## Structured Output\n",
    "\n",
    "Structured output is a great way to force the model to return in a specific way. We use Greedy Decoding params here for more determinist results (Temperature = 1, Top P = 1, Top K = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7841a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    \"\"\"A joke to respond to the user\"\"\"\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline to the joke\")\n",
    "\n",
    "llm = ChatBedrockConverse(\n",
    "    model=\"us.amazon.nova-lite-v1:0\",\n",
    "    temperature=1,\n",
    "    top_p=1,\n",
    "    additional_model_request_fields={\n",
    "        \"inferenceConfig\": {\n",
    "            \"topK\": 1\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "structured_llm = llm.with_structured_output(Joke)\n",
    "structured_llm.invoke(\"Tell me a joke about cats\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
