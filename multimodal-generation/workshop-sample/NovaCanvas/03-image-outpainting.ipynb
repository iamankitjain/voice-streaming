{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95ab40b4-f768-436f-8d9b-9f1f3bf1020b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction to Outpainting\n",
    "\n",
    "With outpainting, you provide an image to be edited as well as a \"mask\" which defines which part of the image should be preserved. The mask may either be provided as a black and white image (`maskImage`) or as a natural language description of what parts of the image to retain (`maskPrompt`). Outpainting can be used to replace the background of an image, placing the image's subject in a whole new environment or special background.\n",
    "\n",
    "### Use Case\n",
    "\n",
    "Now, OctankFashion wants to create a professional-looking ad image featuring this new product in a realistic setting. This is often referred to as \"lifestyle\" imagery. The theme of the lifestyle image will be \"fun at the beach\". The atmosphere we want to evoke is that of a sunny day at the beach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9d7c61-b77a-4333-8978-6a12225dfe57",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Prerequisites:</b> Please run the prerequiresites <b>00-prerequisites.ipynb</b> first before proceeding.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daa2181-3b47-4740-b19a-20d3c3fe6152",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import base64\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "from PIL import Image\n",
    "from utils import save_image, plot_images\n",
    "\n",
    "bedrock_runtime_client = boto3.client(\n",
    "    \"bedrock-runtime\",\n",
    "    region_name=\"us-east-1\",\n",
    "    config=Config(\n",
    "        read_timeout=5 * 60\n",
    "    ),  # IMPORTANT: Increase the read timeout to 5 minutes to support longer operations.\n",
    ")\n",
    "image_generation_model_id = \"amazon.nova-canvas-v1:0\"\n",
    "output_dir = \"output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552500bd-832b-480d-845f-e62b4d4ae155",
   "metadata": {},
   "source": [
    "The following parameters are specific to the \"OUTPAINTING\" task type and are encapsulated in the `outPaintingParams` field of the request body.\n",
    "\n",
    "- `image` (Required) ‚Äì The JPEG or PNG image to modify, encoded as a Base64 string. (See code below for how to encode an image as Base64.)\n",
    "- You must define one of the following fields (but not both) in order to specify the area of the image to affect:\n",
    "  - `maskPrompt` ‚Äì A natural language text prompt that describes the region(s) of the image to edit.\n",
    "  - `maskImage` ‚Äì A black and white image in which pure black pixels indicate the area inside the mask and pure white pixels indicate the area outside the mask. The mask image must be the same dimensions at the input image. Its dimensions must match the dimensions of the input `image`.\n",
    "- `outPaintingMode` ‚Äì There are two outpainting modes which determine how the mask you provide is interpreted.\n",
    "  - ‚ÄúDEFAULT‚Äù ‚Äì This mode transitions smoothly between the masked area and non-masked area, using some of the pixels of the original background as the starting point for the new background. This mode is often best when you would like the new background to use similar colors as the original background near the edges of your mask, but can result in a halo effect if your prompt calls for a new background that will be very different from the original background.\n",
    "  - ‚ÄúPRECISE‚Äù ‚Äì This mode adheres strictly to the mask‚Äôs bounds and is often the best option when you are making more significant changes to the background of your image.\n",
    "\n",
    "The input image and mask image can be of any resolution that meets these requirements:\n",
    "\n",
    "- Each side's length is no shorter than 320 and no longer than 4096\n",
    "- The aspect ratio ranges from 1:4 (portrait) through 4:1 (landscape)\n",
    "- The total number of pixels (width x height) does not exceed 4,194,304 (the equivalent of 2048 x 2048)\n",
    "- The `image` and `maskImage` must have the same resolution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd846428",
   "metadata": {},
   "source": [
    "#### Example 1: Replace background with mask prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c49aaf",
   "metadata": {},
   "source": [
    "Outpaint is a powerful tool when you need to replace the background of one image. As with inpainting, you can choose to provide a mask prompt or mask image to help model identify the region that it should NOT reconstruct. In the example below, we'll use a mask prompt.\n",
    "\n",
    "The best practice when writing a text prompt for background replacement is to describe the _whole_ image that you want to create, including the elements that aren't changing. This gives the model the full context of the scene and results in a more cohesive image.\n",
    "\n",
    "Run the cells below to replace the background of the image. The generated image will be saved to the \"output\" folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6472551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the main input parameters.\n",
    "reference_image_path = \"data/tshirt_palm_tree.png\"\n",
    "mask_prompt = \"shirt\"\n",
    "\n",
    "text = \"a man with tanned skin stands on a beautiful sandy beach wearing a t-shirt, clear sky and surf in the background\"\n",
    "outpainting_mode = \"PRECISE\"  # Either \"DEFAULT\" or \"PRECISE\"\n",
    "\n",
    "seed = 97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47ef970",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(reference_image_path, \"rb\") as image_file:\n",
    "    reference_image_base64 = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# Generate image condition on reference image\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"taskType\": \"OUTPAINTING\",\n",
    "        \"outPaintingParams\": {\n",
    "            \"text\": text,  # A description of the final desired image\n",
    "            \"image\": reference_image_base64,  # The image to edit\n",
    "            \"maskPrompt\": mask_prompt,  # One of \"maskImage\" or \"maskPrompt\" is required\n",
    "            \"outPaintingMode\": outpainting_mode,  # Either \"DEFAULT\" or \"PRECISE\"\n",
    "        },\n",
    "        \"imageGenerationConfig\": {\n",
    "            \"numberOfImages\": 1,  # Number of images to generate, up to 5.\n",
    "            \"cfgScale\": 6.5,  # How closely the prompt will be followed\n",
    "            \"seed\": seed,  # Any number from 0 through 858,993,459\n",
    "            \"quality\": \"standard\",  # Either \"standard\" or \"premium\". Defaults to \"standard\".\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Generating image...\")\n",
    "\n",
    "response = bedrock_runtime_client.invoke_model(\n",
    "    body=body,\n",
    "    modelId=image_generation_model_id,\n",
    "    accept=\"application/json\",\n",
    "    contentType=\"application/json\",\n",
    ")\n",
    "\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "base64_images = response_body.get(\"images\")\n",
    "image_path = f\"{output_dir}/03-outpainting_mask-prompt.png\"\n",
    "save_image(base64_images[0], image_path)\n",
    "\n",
    "print(f\"Image saved to {image_path}\")\n",
    "\n",
    "response_images = [\n",
    "    Image.open(io.BytesIO(base64.b64decode(base64_image)))\n",
    "    for base64_image in base64_images\n",
    "]\n",
    "\n",
    "plot_images(response_images, ref_image_path=reference_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84fcc76",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>üí° Bonus Activity:</strong> Outpainting supports two values for the `outpaintingMode` ‚Äî \"DEFAULT\" and \"PRECISE\". Try both <tt>outpaintingMode</tt> values to observe their effect.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993359af",
   "metadata": {},
   "source": [
    "#### Example 2: Image extension\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415eaf92",
   "metadata": {},
   "source": [
    "Often times, a creator may want to further extend the bounds of an image to satisfy the desired composition or aspect ratio. This is where image extension comes into play, allowing users to seamlessly expand the boundaries of their original image.\n",
    "\n",
    "Let's expand the image to make it ultra wide. We'll position the original image to the right of the expanded image so that we leave plenty of room for the OctankFashion copy writers to add advertising text.\n",
    "\n",
    "The following code is more advanced than the previous examples you've seen so far. Here are the steps the code performs:\n",
    "\n",
    "1. Uses an image library (Pillow) to expand the bounds of the original image to match our desired resolution, filling the new expanded area with solid color pixels. (See the first image below.)\n",
    "2. Uses the same image library to create a mask image which protects the original image pixels from changing. (See the second image below.)\n",
    "3. Uses Nova Canvas outpainting to replace the expanded area with visuals matching your prompt.\n",
    "\n",
    "<img src=\"data/03-outpainting_extension-source.png\" width=\"48%\" style=\"margin: 4px;\"><img src=\"data/03-outpainting_extension-mask.png\" width=\"48%\" style=\"margin: 4px;border: 1px solid #99999955\">\n",
    "\n",
    "Run the cells below to create an expanded version of the original image. The generated images will be saved to the \"output\" folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0b7d06-18c8-4ddb-9523-03e23c962ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the main input parameters.\n",
    "reference_image_path = \"data/tshirt_beach_1024x1024.png\"\n",
    "text = \"a man with tanned skin stands on a beautiful sandy beach wearing a t-shirt, clear sky and surf in the background\"\n",
    "seed = 95\n",
    "\n",
    "# Extension settings\n",
    "target_width = 2048\n",
    "target_height = 1024\n",
    "horizontal_position_percent = 1.0  # Position the original image at far right\n",
    "vertical_position_percent = 0.5  # Center vertically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a97f5b5-7d6b-4f1f-84fc-6c86a7fb5df7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convertImageToPngBase64(image):\n",
    "    \"\"\"\n",
    "    Converts an image to PNG format and returns the base64-encoded\n",
    "    representation of that PNG.\n",
    "    \"\"\"\n",
    "    mem_file = io.BytesIO()\n",
    "    image.save(mem_file, format=\"PNG\")\n",
    "    mem_file.seek(0)\n",
    "    png_bytes = mem_file.read()\n",
    "\n",
    "    return base64.b64encode(png_bytes).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "# Load reference image\n",
    "original_image = Image.open(reference_image_path)\n",
    "original_width, original_height = original_image.size\n",
    "\n",
    "# Calculate the position of the original image on the expanded canvas.\n",
    "position = (\n",
    "    int((target_width - original_width) * horizontal_position_percent),\n",
    "    int((target_height - original_height) * vertical_position_percent),\n",
    ")\n",
    "\n",
    "# Create an input image which contains the original image with an expanded\n",
    "# canvas. Save it for future reference.\n",
    "WHITE = (255, 255, 255)\n",
    "BLACK = (0, 0, 0)\n",
    "input_image = Image.new(\"RGB\", (target_width, target_height), (230, 230, 230))\n",
    "input_image.paste(original_image, position)\n",
    "expanded_image_base64 = convertImageToPngBase64(input_image)\n",
    "\n",
    "# Create mask that matches the canvas size and masks the place where the\n",
    "# original image is positioned.\n",
    "mask_image = Image.new(\"RGB\", (target_width, target_height), WHITE)\n",
    "original_image_shape = Image.new(\"RGB\", (original_width, original_height), BLACK)\n",
    "mask_image.paste(original_image_shape, position)\n",
    "mask_image_base64 = convertImageToPngBase64(mask_image)\n",
    "\n",
    "# Save the expanded image and image mask for demonstratoin.\n",
    "input_image.save(\"output/03-outpainting_extension-source.png\")\n",
    "mask_image.save(\"output/03-outpainting_extension-mask.png\")\n",
    "\n",
    "# Generate image condition on reference image\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"taskType\": \"OUTPAINTING\",\n",
    "        \"outPaintingParams\": {\n",
    "            \"text\": text,\n",
    "            \"image\": expanded_image_base64,\n",
    "            \"maskImage\": mask_image_base64,\n",
    "            \"outPaintingMode\": \"DEFAULT\",\n",
    "        },\n",
    "        \"imageGenerationConfig\": {\n",
    "            \"numberOfImages\": 1,\n",
    "            \"seed\": seed,\n",
    "            \"quality\": \"standard\",\n",
    "            \"cfgScale\": 6.5,\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Generating image...\")\n",
    "\n",
    "response = bedrock_runtime_client.invoke_model(\n",
    "    body=body,\n",
    "    modelId=image_generation_model_id,\n",
    "    accept=\"application/json\",\n",
    "    contentType=\"application/json\",\n",
    ")\n",
    "\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "base64_images = response_body.get(\"images\")\n",
    "image_path = f\"{output_dir}/03-outpainting_extended-image.png\"\n",
    "save_image(base64_images[0], image_path)\n",
    "\n",
    "print(f\"Image saved to {image_path}\")\n",
    "\n",
    "response_images = [\n",
    "    Image.open(io.BytesIO(base64.b64decode(base64_image)))\n",
    "    for base64_image in response_body.get(\"images\")\n",
    "]\n",
    "\n",
    "plot_images(response_images, ref_image_path=reference_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2008f4-9605-4922-ad87-680fe1d92e50",
   "metadata": {},
   "source": [
    "## Take Away\n",
    "\n",
    "Outpainting is a versatile image manipulation technique that extends the capabilities of traditional editing tools. This feature allows users to replace backgrounds or seamlessly expand the boundaries of existing images with remarkable ease. By intelligently generating content beyond the original image borders, outpainting enables creators to extend scenes, add new elements, or completely transform the context of an image. Whether you're looking to widen a landscape photo, adapt an image to different aspect ratios, or replace a mundane background with something more exciting, outpainting offers a powerful solution.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
